{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Similarity_Finder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zantorym/Aidi-capstone-I/blob/main/Final%20code/02_Similarity_Finder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RecSys\n"
      ],
      "metadata": {
        "id": "zpe768b0NmJG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_QbfvVAUFa"
      },
      "source": [
        "## Code Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ1BuYPlrmz6",
        "outputId": "e519aaf2-c55a-46d6-cbc2-8560caaa2c9d"
      },
      "source": [
        "# Timer to measure code execution time\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 2.61 ms (started: 2021-12-11 21:49:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpjEpwqL0BPn",
        "outputId": "ff873404-3fe6-43d1-fb1e-901a25f074cb"
      },
      "source": [
        "# Importing libraries\n",
        "import pickle\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17.5 ms (started: 2021-12-11 21:52:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHxtZ2XI2GMT",
        "outputId": "11819c1d-2766-4e04-9b86-54e2f0129e6d"
      },
      "source": [
        "'''\n",
        "Constants used throughout the program\n",
        "\n",
        "These constants include file paths as well as options for whether to apply\n",
        "certain pre-processing and processing techniques. This was implemented so that\n",
        "the program could be as modular as possible, allowing us to test various\n",
        "combinations of techniques in order to find the most effective ones.\n",
        "'''\n",
        "\n",
        "# Pickle Input\n",
        "JD_FILES_PICKLE_OUTPATH='/content/drive/MyDrive/Durham College/Capstone - I/data/Datasets/jds.pickle'\n",
        "RESUME_FILES_PICKLE_OUTPATH='/content/drive/MyDrive/Durham College/Capstone - I/data/Datasets/resumes.pickle'\n",
        "\n",
        "# Test file path\n",
        "EVAL_MATRIX_FILE_PATH = '/content/drive/MyDrive/Durham College/Capstone - I/Evaluation_Matrix.xlsx'\n",
        "\n",
        "# Tokenization\n",
        "'''\n",
        "0 - string split\n",
        "1 - NLTK TreebankWordTokenizer\n",
        "Note: not defined value = 0 = string split\n",
        "'''\n",
        "TOKENIZATION_ALGORITHM=0\n",
        "\n",
        "\n",
        "# NGrams\n",
        "NGRAM_COUNT=1 # Number of n-grams\n",
        "\n",
        "# Stop Words\n",
        "FILTER_STOP_WORDS=1 # 1 to filter stop words, 0 to not filter stop words\n",
        "\n",
        "# The Source for stop words\n",
        "'''\n",
        "1 - Use NLTK stop words\n",
        "2 - Use Scikit Learn stop words\n",
        "Note: not defined value = 0 = intersection of both NLTK and Scikit-learn\n",
        "'''\n",
        "STOP_WORDS_SOURCE=0\n",
        "\n",
        "# Case Folding\n",
        "# Note: case folding is always performed as job description and resumes\n",
        "#       should have minimal use of proper nouns for differentiating against \n",
        "#       common words.\n",
        "\n",
        "# Stemming\n",
        "STEMMER_ALGORITHM=0\n",
        "'''\n",
        "1 = Use Porter stemmer\n",
        "2 = Use Snowball stemmer\n",
        "Note: not defined value = 0 = no stemming performed\n",
        "'''\n",
        "\n",
        "# Lemmatization\n",
        "# Note: Cannot perform lematization as punctuation is removed from source text.\n",
        "#       Lemmatization requires parts of speech to work properly.\n",
        "\n",
        "# Filtering non-alphabetic tokens\n",
        "'''\n",
        "0 = Don't filter\n",
        "1 = Filter\n",
        "'''\n",
        "FILTER_NON_ALPHANUMERIC_TOKENS = 1\n",
        "\n",
        "PREPROCESS_METHOD = 1 # 0 if we don't want to pre-process, 1 if we want to pre-process\n",
        "VECTORIZATION_METHOD = 1 # 0 for TF-IDF, 1 for bag of words\n",
        "SIMILARITY_METHOD = 0 # 0 for cosine similarity, 1 for euclidean distance"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17.1 ms (started: 2021-12-11 21:49:37 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4oa7KZWBhcm",
        "outputId": "ed384200-cf16-45df-c031-a0f6ddb8f870"
      },
      "source": [
        "# Attaching google drive to colab instance\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 34.7 s (started: 2021-12-11 21:49:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "OV7AR_35Qm_n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4Ph-9wh2IT8",
        "outputId": "5383075d-fc69-4db2-b188-c8d62455abd2"
      },
      "source": [
        "# Loading the dataset from pickled files\n",
        "jd_files_dict = resume_files_dict = {}\n",
        "with open(JD_FILES_PICKLE_OUTPATH, 'rb') as fh:\n",
        "  jd_files_dict = pickle.load(fh)\n",
        "with open(RESUME_FILES_PICKLE_OUTPATH, 'rb') as fh:\n",
        "  resume_files_dict = pickle.load(fh)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.08 s (started: 2021-12-11 21:50:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Count of JDs:', len(jd_files_dict))\n",
        "print('Count of Resumes:', len(resume_files_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skz5lDUvRBLJ",
        "outputId": "0691ffe2-b3ed-4440-b49c-2026662e5ddc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of JDs: 151210\n",
            "Count of Resumes: 50023\n",
            "time: 1.96 ms (started: 2021-12-11 21:50:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tokenization function used in vectorization\n",
        "\n",
        "args:\n",
        "  * text - the input text to be tokenized\n",
        "\n",
        "returns:\n",
        "  * A string of the tokens that represent the text\n",
        "'''\n",
        "def tokenize(text):\n",
        "  # Choosing the list of stop words to choose\n",
        "  if FILTER_STOP_WORDS == 1:\n",
        "    if STOP_WORDS_SOURCE != 2:\n",
        "      nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
        "    \n",
        "    if STOP_WORDS_SOURCE != 1:\n",
        "      from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
        "\n",
        "    if STOP_WORDS_SOURCE == 1:\n",
        "      stop_words = nltk_stop_words\n",
        "    elif STOP_WORDS_SOURCE == 2:\n",
        "      stop_words = sklearn_stop_words\n",
        "    else:\n",
        "      stop_words = sklearn_stop_words.intersection(nltk_stop_words)\n",
        "\n",
        "  # Choosing the stemmer algorithm to use\n",
        "  if STEMMER_ALGORITHM == 1 or STEMMER_ALGORITHM == 2:\n",
        "    from nltk.stem.snowball import SnowballStemmer\n",
        "    if STEMMER_ALGORITHM == 1:\n",
        "      stemmer = SnowballStemmer(language='porter')\n",
        "    elif STEMMER_ALGORITHM == 2:\n",
        "      stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "  tokenized = [] # Variable to store the tokenized version of input text\n",
        "  \n",
        "  # Tokenizing the words and converting them to lowercase\n",
        "  if TOKENIZATION_ALGORITHM == 1:\n",
        "    tokenized = TreebankWordTokenizer().tokenize(text.lower())\n",
        "  else:\n",
        "    tokenized = text.lower().split()\n",
        "\n",
        "  # Filtering stop words and words of length less than 2\n",
        "  if FILTER_STOP_WORDS == 1:\n",
        "    tokenized = [token for token in tokenized if (token not in stop_words and len(token)>1)]\n",
        "\n",
        "  # Applying the stemmer algorithm\n",
        "  if STEMMER_ALGORITHM == 1 or STEMMER_ALGORITHM == 2:\n",
        "    tokenized = [stemmer.stem(token) for token in tokenized]\n",
        "\n",
        "  # Applying ngrams\n",
        "  if NGRAM_COUNT > 1:\n",
        "    # Handle files that are \"empty\", i.e. contains only spaces\n",
        "    if len(tokenized) == 0:\n",
        "      ngram_tokens = []\n",
        "    else:\n",
        "      ngram_tokens = [' '.join(t) for t in ngrams(tokenized, NGRAM_COUNT)]\n",
        "    tokenized += ngram_tokens\n",
        "\n",
        "  if FILTER_NON_ALPHANUMERIC_TOKENS == 1:\n",
        "    tokenized = [token for token in tokenized if (all(char.isalpha() or char.isdigit() for char in token) and any(char.isalpha() for char in token))] # Only aplhanumeric tokens that contain at least one alphabet\n",
        "\n",
        "  string = ' '.join(tokenized) # Convert vectorized list to string\n",
        "\n",
        "  return string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGkqipYuRB2X",
        "outputId": "816adf51-d998-4f36-efc8-7c07c24fb45f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 39.5 ms (started: 2021-12-11 21:53:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGiKIjvfrWB3",
        "outputId": "5413253e-ae56-47f0-c681-e85b947de2f2"
      },
      "source": [
        "# Combining both corpuses in to one dictionary\n",
        "combined_files_dict = {}\n",
        "for filename in jd_files_dict:\n",
        "  modified_fn = 'jd:' + filename\n",
        "  if len(jd_files_dict[filename].strip()) == 0:\n",
        "    continue\n",
        "  combined_files_dict[modified_fn] = jd_files_dict[filename]\n",
        "for filename in resume_files_dict:\n",
        "  modified_fn = 'rs:' + filename\n",
        "  if len(resume_files_dict[filename].strip()) == 0:\n",
        "    continue\n",
        "  combined_files_dict[modified_fn] = resume_files_dict[filename]\n",
        "\n",
        "# Storing the filenames in a list\n",
        "jd_filenames = [key for key in combined_files_dict.keys() if key.startswith('jd:')]\n",
        "resume_filenames = [key for key in combined_files_dict.keys() if key.startswith('rs:')]\n",
        "\n",
        "# Converting corpus from dictionary to dataframe\n",
        "corpus_raw = pd.DataFrame.from_dict(combined_files_dict, orient='index', columns=['text'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 415 ms (started: 2021-12-11 21:51:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpry8w6asRY5",
        "outputId": "f4e96543-daeb-4570-e088-24981b93dcbc"
      },
      "source": [
        "# Applying some pre-processing and tokenization to the dataset\n",
        "if PREPROCESS_METHOD == 1:\n",
        "  corpus_raw['text'] = corpus_raw['text'].apply(tokenize)\n",
        "\n",
        "# Applying vectorization\n",
        "if VECTORIZATION_METHOD == 0:\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  corpus_vectors = vectorizer.fit_transform(corpus_raw['text'])\n",
        "else:\n",
        "  vectorizer = CountVectorizer()\n",
        "  corpus_vectors = vectorizer.fit_transform(corpus_raw['text'])\n",
        "\n",
        "corpus_filenames = corpus_raw.index.values # List of file names in the corpus"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2min 28s (started: 2021-12-11 21:53:09 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybpNV98AZFYk"
      },
      "source": [
        "## Loading test files for evaluation of models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSCk3xuUP2Np",
        "outputId": "42055fae-52a7-44a3-f606-8330b4c383d4"
      },
      "source": [
        "eval_matrix = pd.ExcelFile(EVAL_MATRIX_FILE_PATH)\n",
        "jd2jd = pd.read_excel(eval_matrix, 'JD_2_JD') # JD_2_JD testing dataset\n",
        "r2r = pd.read_excel(eval_matrix, 'Resume_2_Resume') # Resume_2_Resume testing dataset\n",
        "jd2r = pd.read_excel(eval_matrix, 'JD_2_Resume') # JD_2_Resume testing dataset\n",
        "r2jd = pd.read_excel(eval_matrix, 'Resume_2_JD') # Resume_2_JD testing dataset\n",
        "\n",
        "jd2jd = jd2jd.drop('Contributer', axis=1) # Removing the contributer column\n",
        "jd2jd.set_index('Query_File_ID', inplace=True) # Makining Query_File_ID the index\n",
        "\n",
        "r2r = r2r.drop('Contributor', axis=1) # Removing the contributer column\n",
        "r2r.set_index('Query_File_ID', inplace=True) # Makining Query_File_ID the index\n",
        "\n",
        "jd2r = jd2r.drop('Contributor', axis=1) # Removing the contributer column\n",
        "jd2r.set_index('Query_File_ID', inplace=True) # Makining Query_File_ID the index\n",
        "\n",
        "r2jd = r2jd.drop('Contributor', axis=1) # Removing the contributer column\n",
        "r2jd.set_index('Query_File_ID', inplace=True) # Makining Query_File_ID the index"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 444 ms (started: 2021-12-11 21:55:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXwIa_sknhOx"
      },
      "source": [
        "## Similarity score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0i36MaUW8uX",
        "outputId": "33e9e677-6891-4be4-f9db-bb4d8c8ff2a7"
      },
      "source": [
        "def find_similarity(test_file, jd_or_resume = 0):\n",
        "  \"\"\"\n",
        "  Given a test file, it returns the similarity score against that file for all JDs/Resumes\n",
        "\n",
        "  params:\n",
        "    test_file: One entry from the corpus representing a JD or Resume\n",
        "    jd_or_resume: Whether to compare against JDs or to compare against resumes\n",
        "                  0 - JDs\n",
        "                  1 - Resumes\n",
        "  \n",
        "  returns: A pandas dataframe containing the similarity scores of all the required files\n",
        "  \"\"\"\n",
        "\n",
        "  sample_index = np.where(corpus_filenames == test_file)[0][0]\n",
        "  sample = corpus_vectors[sample_index]\n",
        "  \n",
        "  test_output = []\n",
        "  if SIMILARITY_METHOD == 0:\n",
        "    test_output = cosine_similarity(corpus_vectors, sample)\n",
        "  else:\n",
        "    test_output = euclidean_distances(corpus_vectors, sample)\n",
        "\n",
        "  test = pd.DataFrame(test_output, index = corpus_filenames, columns = ['similarity'])\n",
        "\n",
        "  if jd_or_resume == 0:\n",
        "    test = test.loc[ jd_filenames, : ]\n",
        "  else:\n",
        "    test = test.loc[ resume_filenames, : ]\n",
        "\n",
        "  if SIMILARITY_METHOD == 0:\n",
        "    test.sort_values(by=['similarity'], ascending = False, inplace = True) # Cosine\n",
        "  else:\n",
        "    test.sort_values(by=['similarity'], ascending = True, inplace = True) # Euclidean\n",
        "\n",
        "  return test"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.1 ms (started: 2021-12-11 21:55:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_YF7qRHnj8D"
      },
      "source": [
        "## MAP Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43yuFGLpKurv",
        "outputId": "b7c33460-e8b0-4768-de9a-2d4f296b7ed6"
      },
      "source": [
        "def generate_MAP_input(test_file_type = 0):\n",
        "  \"\"\"\n",
        "  Generates the two inputs required for calculating the MAP score\n",
        "\n",
        "  params:\n",
        "          test_file_type: which of the 4 test files it is (default = 0)\n",
        "                          0 - JD_2_JD\n",
        "                          1 - Resume_2_Resume\n",
        "                          2 - JD_2_Resume\n",
        "                          3 - Resume_2_JD\n",
        "\n",
        "  returns:\n",
        "          the two inputs for the MAP score function\n",
        "  \"\"\"\n",
        "  actual = []\n",
        "  predicted = []\n",
        "\n",
        "  test_file = []\n",
        "  ind_prefix = ''\n",
        "  res_prefix = ''\n",
        "  jd_or_resume = 0\n",
        "\n",
        "  if test_file_type == 0:\n",
        "    test_file = jd2jd\n",
        "    ind_prefix = 'jd:'\n",
        "    res_prefix = 'jd:'\n",
        "  elif test_file_type == 1:\n",
        "    test_file = r2r\n",
        "    ind_prefix = 'rs:'\n",
        "    res_prefix = 'rs:'\n",
        "    jd_or_resume = 1\n",
        "  elif test_file_type == 2:\n",
        "    test_file = jd2r\n",
        "    ind_prefix = 'jd:'\n",
        "    res_prefix = 'rs:'\n",
        "    jd_or_resume = 1\n",
        "  else:\n",
        "    test_file = r2jd\n",
        "    ind_prefix = 'rs:'\n",
        "    res_prefix = 'jd:'\n",
        "\n",
        "  for index, row in test_file.iterrows():\n",
        "    # List of files relevant to the query file in the testing document\n",
        "    try: # Had to implement a try-except statement because sometimes there are multiple entries for one file (eg. line 141 and 142 of JD_2_JD are the same)\n",
        "      relevant_files = test_file.loc[index].tolist()\n",
        "    except:\n",
        "      relevant_files = test_file.loc[index].iloc[0].tolist() # we select the first entry from the list of entries in the testing dataset\n",
        "    relevant_files = [res_prefix + file for file in relevant_files if not(pd.isnull(file))]\n",
        "\n",
        "    \n",
        "    # Finding files relevant to the query file using our code\n",
        "    test = find_similarity(ind_prefix + index, jd_or_resume)\n",
        "\n",
        "    # Removing top result if it is the same as the query file\n",
        "    if test.index[0] == ind_prefix + index:\n",
        "      test = test.iloc[1: , :]\n",
        "\n",
        "    predicted_files = test.head(len(relevant_files)).index # Getting the top predicted files\n",
        "\n",
        "    actual.append(relevant_files)\n",
        "    predicted.append(predicted_files)\n",
        "\n",
        "  return predicted, actual"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 33.5 ms (started: 2021-12-11 21:55:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjxsjNWuLAV4",
        "outputId": "d24a7cf3-acea-49fa-9cff-ae2c3f405496"
      },
      "source": [
        "\"\"\"\n",
        "A function to calcualte the precision@k.\n",
        "\n",
        "Input: Two lists and a number.\n",
        "      - 'predicted' is the list of file names that our algorithm generates in response to a specific query\n",
        "      - 'actual' is the list of file names that our AI algorithm is supposed to return\n",
        "      - 'k' is the k-index for which we're supposed to calculate the precision@k\n",
        "\n",
        "Output: A number denoting the precision@k\n",
        "\"\"\"\n",
        "\n",
        "def precision_at_k(predicted, actual, k):\n",
        "    act_set = set(actual)\n",
        "    pred_set = set(predicted[:k])\n",
        "    result = len(act_set & pred_set) / float(k)\n",
        "    return result"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.17 ms (started: 2021-12-11 21:55:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdtLyiZULPkI",
        "outputId": "4a329e79-cb13-478a-9c34-a4d61493e1e0"
      },
      "source": [
        "\"\"\"\n",
        "A function to calculate the average precision for a specific query.\n",
        "\n",
        "Input: Two lists.\n",
        "      - 'predicted' is the list of file names that our algorithm generates in response to a specific query\n",
        "      - 'actual' is the list of file names that our AI algorithm is supposed to return\n",
        "\n",
        "Output: A number denoting the average precision for a query.\n",
        "\n",
        "Things to check for: If the length of our predicted array is less than the length of our actual array, the code will fail (ideally this shouldn't happen, and should be checked for before calling the map score function)\n",
        "\"\"\"\n",
        "\n",
        "def avg_precision(predicted, actual):\n",
        "  avg_prec = 0\n",
        "  n = 0\n",
        "\n",
        "  for i in range(len(actual)):\n",
        "    if predicted[i] == actual[i]:\n",
        "      avg_prec += precision_at_k(predicted, actual, i+1)\n",
        "      n += 1\n",
        "  \n",
        "  if n>0:\n",
        "    avg_prec /= n\n",
        "  \n",
        "  return avg_prec"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.7 ms (started: 2021-12-11 21:55:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ2VwUJSUhqc",
        "outputId": "d67ee75a-72f4-46ad-93e8-c1ff2b68cbdd"
      },
      "source": [
        "\"\"\"\n",
        "A function to calculate the Mean Average Precision (MAP) Score for the entire testing dataset.\n",
        "\n",
        "Input: Two 2D Lists. \n",
        "      - 'predicted' is the list of list of file names that our algorithm generates. Each list corresponds to one input\n",
        "      - 'actual' is the list of list of file names that we're supposed to get. Each list corresponds to one input\n",
        "\n",
        "Output: A number denoting the map_score\n",
        "\"\"\"\n",
        "\n",
        "def score(predicted, actual):\n",
        "  map_score = 0\n",
        "  n = 0\n",
        "\n",
        "  for i in range(len(actual)):\n",
        "    map_score += avg_precision(predicted[i], actual[i])\n",
        "    n += 1\n",
        "\n",
        "  if n>0:\n",
        "    map_score /= n\n",
        "  \n",
        "  return map_score"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.51 ms (started: 2021-12-11 21:55:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the MAP Score on the test set\n",
        "\n",
        "Based on the options set for which pre-processing and processing methods to use (in particular the variables PREPROCESS_METHOD, VECTORIZATION_METHOD, and SIMILARITY_METHOD), this part shows you the MAP scores corresponding to the 4 test sets. For the best combination of these methods, refer to the final report."
      ],
      "metadata": {
        "id": "5_kHJ5gnb6Pt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6_dUq4dVwNP",
        "outputId": "0a4fe827-6578-4904-8df6-a83a6489c4bf"
      },
      "source": [
        "# For JD_2_JD\n",
        "predicted, actual = generate_MAP_input(0)\n",
        "print(\"JD-2-JD score: \", score(predicted, actual))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JD-2-JD score:  0.05444659776055125\n",
            "time: 2min 49s (started: 2021-12-09 05:23:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhCunqmdidsM",
        "outputId": "887cd157-d29c-4702-9d52-150994122a74"
      },
      "source": [
        "# For Resume_2_Resume\n",
        "predicted, actual = generate_MAP_input(1)\n",
        "print(\"Resume-2-Resume score: \", score(predicted, actual))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume-2-Resume score:  0.021722846441947566\n",
            "time: 1min 49s (started: 2021-12-09 05:26:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwuV-JrDilyX",
        "outputId": "120044fe-7b94-4b02-c4ae-fe209fcf7c08"
      },
      "source": [
        "# For JD_2_Resume\n",
        "predicted, actual = generate_MAP_input(2)\n",
        "print(\"JD-2-Resume score: \", score(predicted, actual))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JD-2-Resume score:  0.0\n",
            "time: 23.6 s (started: 2021-12-09 05:27:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsuuvWm2isBi",
        "outputId": "0da4b622-f1bd-454d-d75d-c97289b3df40"
      },
      "source": [
        "# For Resume_2_JD\n",
        "predicted, actual = generate_MAP_input(3)\n",
        "print(\"Resume-2-JD score: \", score(predicted, actual))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume-2-JD score:  0.0\n",
            "time: 55.5 s (started: 2021-12-09 05:28:16 +00:00)\n"
          ]
        }
      ]
    }
  ]
}
